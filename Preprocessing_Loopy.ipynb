{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2da3a3ea-229c-42c7-b64e-e5a7ac10d815",
   "metadata": {},
   "source": [
    "### Preprocess all data in a loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7112d221-7f31-4001-b42e-687325823b55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing DYAD02F_...\n",
      "Success: No NaN values remain in the DataFrame after interpolation.\n",
      "Saved processed data to /Users/ruzenkakaldenbach/Desktop/Behaviour/Loopy_preprocessed_data/Loopy_DYAD02F__processed.csv.\n",
      "All datasets processed.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from scipy.interpolate import interp1d\n",
    "import os\n",
    "\n",
    "# List of dataset names\n",
    "dataset_names = [\n",
    "    \"DYAD02F_\"#, \"DYAD06F_\", \"DYAD06NF_\", \"DYAD10F_\", \"DYAD10NF_\", \"DYAD11F_\",\n",
    "    #\"DYAD11NF_\", \"DYAD12F_\", \"DYAD12NF_\", \"DYAD14F_\", \"DYAD14NF_\", \"DYAD15F_\",\n",
    "    #\"DYAD15I_\", \"DYAD15NF_\", \"DYAD16F_\", \"DYAD16I_\", \"DYAD16NF_\", \"DYAD18F_\",\n",
    "    #\"DYAD18I_\", \"DYAD18NF_\", \"DYAD21F_\", \"DYAD21NF_\", \"DYAD23F_\", \"DYAD23NF_\",\n",
    "    #\"DYAD24F_\", \"DYAD24NF_\"\n",
    "]\n",
    "\n",
    "# Base directories for input and output\n",
    "base_dir = \"/Users/ruzenkakaldenbach/Desktop/Behaviour/raw_data_transformed/\"\n",
    "output_dir = \"/Users/ruzenkakaldenbach/Desktop/Behaviour/Loopy_preprocessed_data/\"\n",
    "\n",
    "# Path to scaling file\n",
    "scaling_file_path = \"/Users/ruzenkakaldenbach/Desktop/Drive/DESK_Measurements_ALL_with_scaling.xlsx\"\n",
    "\n",
    "# Load the scaling file\n",
    "PixDistConvert = pd.read_excel(scaling_file_path)\n",
    "\n",
    "# Define the function to calculate unit vectors\n",
    "def unit_vector(vector):\n",
    "    \"\"\"Returns the unit vector of the given vector.\"\"\"\n",
    "    magnitude = np.linalg.norm(vector)  # Compute the magnitude (length) of the vector\n",
    "    if magnitude == 0:  # Avoid division by zero\n",
    "        return np.array([0, 0])  # Return a zero vector if the magnitude is zero\n",
    "    return vector / magnitude  # Normalize the vector by dividing by its magnitude\n",
    "\n",
    "# Define the function to calculate the angle between two unit vectors\n",
    "def angle_between(v1, v2):\n",
    "    \"\"\"Returns the angle in radians between two unit vectors.\"\"\"\n",
    "    # Clip the dot product to avoid numerical errors and compute the angle\n",
    "    return np.arccos(np.clip(np.dot(v1, v2), -1.0, 1.0))\n",
    "\n",
    "# Define window size in seconds\n",
    "window_size = 10  # 5 seconds before + 5 seconds after\n",
    "window_frames = int(window_size / 0.25)  # Convert to frames (each frame = 0.25s) = 40 frames per 10s window\n",
    "\n",
    "# Function to calculate moving correlation\n",
    "def calculate_moving_correlation(df, col1, col2, window_frames):\n",
    "    correlations = [None] * (window_frames // 2)  # Initialize the list and assign None-value for first 20 rows (5 seconds)\n",
    "    \n",
    "    for i in range(window_frames // 2, len(df) - window_frames // 2): \n",
    "        # i=20 means from row 21 since index i starts from 0 we have an additional row\n",
    "        # stop earlier to prevent correlations being longer than df\n",
    "        window_df = df.iloc[i - window_frames // 2: i + window_frames // 2] # extract the window centred around i +/-20s\n",
    "        if window_df[col1].isna().any() or window_df[col2].isna().any():\n",
    "            warnings.warn(f\"NaN detected in window for i={i} ({col1}, {col2})\", UserWarning)\n",
    "            correlations.append(None)  # append to the end of the list\n",
    "        else:\n",
    "            correlations.append(window_df[col1].corr(window_df[col2])) # compute correlations and append to the end of the list\n",
    "\n",
    "    correlations.extend([None] * (window_frames // 2))  # Modify the existing list by replacing values with None-value for last 20 rows (5 seconds)\n",
    "    return correlations\n",
    "\n",
    "# Define the function to process a single dataset\n",
    "def process_dataset(dat_name):\n",
    "    file_path = f\"{base_dir}{dat_name}adjusted.xlsx\"\n",
    "    \n",
    "    # Skip processing if file does not exist\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"Skipping {dat_name}: File not found at {file_path}\")\n",
    "        return\n",
    "    print(f\"Processing {dat_name}...\")\n",
    "    dat_raw = pd.read_excel(file_path)\n",
    "\n",
    "    # Extract the scaling factor for the current dataset\n",
    "    scaling_factor = PixDistConvert.loc[PixDistConvert['Group'] == dat_name, 'Conversion 1px to mm'].values[0]\n",
    "\n",
    "    # When initializing DF, explicitly specify the data types for each column. \n",
    "    # This ensures that columns remain in the desired structure even if rows with all NaN values are concatenated.\n",
    "    # The warning arises because Pandas plans to handle all-NaN rows differently in future versions.\n",
    "    # Currently, it excludes all-NaN columns during concatenation for performance reasons. In the future, it will retain them.\n",
    "    DF = pd.DataFrame({\n",
    "        'xrc': pd.Series(dtype=float),\n",
    "        'yrc': pd.Series(dtype=float),\n",
    "        'xrf': pd.Series(dtype=float),\n",
    "        'yrf': pd.Series(dtype=float),\n",
    "        'xbc': pd.Series(dtype=float),\n",
    "        'ybc': pd.Series(dtype=float),\n",
    "        'xbf': pd.Series(dtype=float),\n",
    "        'ybf': pd.Series(dtype=float),\n",
    "        'xyc': pd.Series(dtype=float),\n",
    "        'yyc': pd.Series(dtype=float),\n",
    "        'xyf': pd.Series(dtype=float),\n",
    "        'yyf': pd.Series(dtype=float),\n",
    "        'frame_timestamp': pd.Series(dtype=float)\n",
    "    })\n",
    "\n",
    "    # Create an array with steps of 0.25 seconds until the max timestamp\n",
    "    Seconds_025 = np.arange(0, int(np.max(dat_raw['frame_timestamp'])), 0.25)\n",
    "\n",
    "    # Map the color codes to their prefixes\n",
    "    color_map = {\n",
    "        'r': 'red',  # 'r' is mapped to 'red'\n",
    "        'b': 'blue',  # 'b' is mapped to 'blue'\n",
    "        'y': 'yellow'  # 'y' is mapped to 'yellow'\n",
    "    }\n",
    "\n",
    "    # Loop through each interval in Seconds_025\n",
    "    for sec in Seconds_025:\n",
    "        # Filter data for the current time range [sec, sec+0.25)\n",
    "        dd = dat_raw[(dat_raw['frame_timestamp'] >= sec) & (dat_raw['frame_timestamp'] < sec + 0.25)]\n",
    "\n",
    "        # Initialize a row for the current second\n",
    "        row = {'frame_timestamp': sec}\n",
    "\n",
    "        # Process each color (red, blue, yellow)\n",
    "        for color_code, color_name in color_map.items():\n",
    "            # Extract the data for center and front dots for the current color\n",
    "            datcenter = dd[['x_tr', 'y_tr']][dd['name'].str.contains(f'{color_name}_center')]\n",
    "            datfront = dd[['x_tr', 'y_tr']][dd['name'].str.contains(f'{color_name}_front')]\n",
    "\n",
    "            if len(datcenter) > 0 and len(datfront) > 0:  # If both center and front dots exist\n",
    "                # Calculate the mean x_tr and y_tr coordinates for center and front dots\n",
    "                row[f'x{color_code}c'] = np.mean(datcenter['x_tr'])\n",
    "                row[f'y{color_code}c'] = np.mean(datcenter['y_tr'])\n",
    "                row[f'x{color_code}f'] = np.mean(datfront['x_tr'])\n",
    "                row[f'y{color_code}f'] = np.mean(datfront['y_tr'])\n",
    "\n",
    "        # Append the row to the DataFrame\n",
    "        DF = pd.concat([DF, pd.DataFrame([row])], ignore_index=True)\n",
    "\n",
    "    # Define a function to interpolate missing values in a column\n",
    "    def interpolate_column_by_index(df, column_name):\n",
    "        valid_idx = df.index[~df[column_name].isna()]  # Get indices with valid values\n",
    "        valid_values = df[column_name][~df[column_name].isna()]  # Extract valid values\n",
    "        f = interp1d(valid_idx, valid_values, kind='linear', fill_value='extrapolate')  # Linear interpolation\n",
    "        df[column_name] = f(df.index)  # Apply interpolation to all rows\n",
    "        return df\n",
    "\n",
    "    # Interpolate missing values for all coordinate columns\n",
    "    coordinate_columns = [col for col in DF.columns if col != 'frame_timestamp']\n",
    "    for column in coordinate_columns:\n",
    "        DF = interpolate_column_by_index(DF, column)\n",
    "\n",
    "        # After interpolation step\n",
    "    if DF.isna().any().any():\n",
    "        print(\"Error: Interpolation did not fill all NaN values.\")\n",
    "        print(DF[DF.isna().any(axis=1)])  # Print rows with NaN values\n",
    "        raise ValueError(\"Interpolation failed to fill all missing values.\")\n",
    "    else:\n",
    "        print(\"Success: No NaN values remain in the DataFrame after interpolation.\")\n",
    "\n",
    "    # Calculate distances between dyads (actual distances of center and front dots)\n",
    "    DF['dist_c_rb'] = np.sqrt((DF['xrc'] - DF['xbc'])**2 + (DF['yrc'] - DF['ybc'])**2)\n",
    "    DF['dist_c_ry'] = np.sqrt((DF['xrc'] - DF['xyc'])**2 + (DF['yrc'] - DF['yyc'])**2)\n",
    "    DF['dist_c_by'] = np.sqrt((DF['xbc'] - DF['xyc'])**2 + (DF['ybc'] - DF['yyc'])**2)\n",
    "    \n",
    "    DF['dist_f_rb'] = np.sqrt((DF['xrf'] - DF['xbf'])**2 + (DF['yrf'] - DF['ybf'])**2)\n",
    "    DF['dist_f_ry'] = np.sqrt((DF['xrf'] - DF['xyf'])**2 + (DF['yrf'] - DF['yyf'])**2)\n",
    "    DF['dist_f_by'] = np.sqrt((DF['xbf'] - DF['xyf'])**2 + (DF['ybf'] - DF['yyf'])**2)\n",
    "\n",
    "    # Apply scaling factor to all distance columns\n",
    "    distance_columns = [\n",
    "        'dist_c_rb', 'dist_c_ry', 'dist_c_by',\n",
    "        'dist_f_rb', 'dist_f_ry', 'dist_f_by'\n",
    "    ]\n",
    "    DF[distance_columns] = DF[distance_columns] * scaling_factor\n",
    "\n",
    "    # Check for equal distances and raise warnings\n",
    "    if (DF['dist_c_ry'] == DF['dist_f_ry']).any():\n",
    "        warnings.warn(\"Some rows have equal distances for central and front dots in Red-Yellow dyad (dist_c_ry == dist_f_ry).\")\n",
    "    \n",
    "    if (DF['dist_c_by'] == DF['dist_f_by']).any():\n",
    "        warnings.warn(\"Some rows have equal distances for central and front dots in Blue-Yellow dyad (dist_c_by == dist_f_by).\")\n",
    "    \n",
    "    if (DF['dist_c_rb'] == DF['dist_f_rb']).any():\n",
    "        warnings.warn(\"Some rows have equal distances for central and front dots in Red-Blue dyad (dist_c_rb == dist_f_rb).\")\n",
    "\n",
    "\n",
    "    # Determine whether children are \"facing\" or \"backing\" each other\n",
    "    DF['facing_ry'] = np.where(DF['dist_c_ry'] > DF['dist_f_ry'], 1, 0)\n",
    "    DF['facing_by'] = np.where(DF['dist_c_by'] > DF['dist_f_by'], 1, 0)\n",
    "    DF['facing_rb'] = np.where(DF['dist_c_rb'] > DF['dist_f_rb'], 1, 0)\n",
    "\n",
    "    # Add head orientation vectors based on center and front dots\n",
    "    DF['vect_x_r'] = DF['xrf'] - DF['xrc']  # Horizontal vector for red\n",
    "    DF['vect_y_r'] = DF['yrf'] - DF['yrc']  # Vertical vector for red\n",
    "\n",
    "    DF['vect_x_b'] = DF['xbf'] - DF['xbc']  # Horizontal vector for blue\n",
    "    DF['vect_y_b'] = DF['ybf'] - DF['ybc']  # Vertical vector for blue\n",
    "\n",
    "    DF['vect_x_y'] = DF['xyf'] - DF['xyc']  # Horizontal vector for yellow\n",
    "    DF['vect_y_y'] = DF['yyf'] - DF['yyc']  # Vertical vector for yellow\n",
    "\n",
    "    # Compute unit vectors for red, blue, and yellow\n",
    "    DF['unit_vect_x_r'], DF['unit_vect_y_r'] = zip(*DF.apply(lambda row: unit_vector([row['vect_x_r'], row['vect_y_r']]), axis=1))\n",
    "    DF['unit_vect_x_b'], DF['unit_vect_y_b'] = zip(*DF.apply(lambda row: unit_vector([row['vect_x_b'], row['vect_y_b']]), axis=1))\n",
    "    DF['unit_vect_x_y'], DF['unit_vect_y_y'] = zip(*DF.apply(lambda row: unit_vector([row['vect_x_y'], row['vect_y_y']]), axis=1))\n",
    "\n",
    "    # Compute angles in degrees for each dyad\n",
    "    DF['deg_ry'] = DF.apply(lambda row: np.rad2deg(angle_between(\n",
    "        [row['unit_vect_x_r'], row['unit_vect_y_r']],\n",
    "        [row['unit_vect_x_y'], row['unit_vect_y_y']]\n",
    "    )), axis=1)\n",
    "\n",
    "    DF['deg_rb'] = DF.apply(lambda row: np.rad2deg(angle_between(\n",
    "        [row['unit_vect_x_r'], row['unit_vect_y_r']],\n",
    "        [row['unit_vect_x_b'], row['unit_vect_y_b']]\n",
    "    )), axis=1)\n",
    "\n",
    "    DF['deg_by'] = DF.apply(lambda row: np.rad2deg(angle_between(\n",
    "        [row['unit_vect_x_b'], row['unit_vect_y_b']],\n",
    "        [row['unit_vect_x_y'], row['unit_vect_y_y']]\n",
    "    )), axis=1)\n",
    "\n",
    "        # Compute mean positions for each color (center and front combined)\n",
    "    DF['xb'] = (DF['xbc'] + DF['xbf']) / 2\n",
    "    DF['yb'] = (DF['ybc'] + DF['ybf']) / 2\n",
    "    DF['xy'] = (DF['xyc'] + DF['xyf']) / 2\n",
    "    DF['yy'] = (DF['yyc'] + DF['yyf']) / 2\n",
    "    DF['xr'] = (DF['xrc'] + DF['xrf']) / 2\n",
    "    DF['yr'] = (DF['yrc'] + DF['yrf']) / 2\n",
    "    \n",
    "    # Compute moving correlations between dyads\n",
    "    DF['x_corr_ry'] = calculate_moving_correlation(DF, 'xr', 'xy', window_frames)\n",
    "    DF['y_corr_ry'] = calculate_moving_correlation(DF, 'yr', 'yy', window_frames)\n",
    "    DF['x_corr_by'] = calculate_moving_correlation(DF, 'xb', 'xy', window_frames)\n",
    "    DF['y_corr_by'] = calculate_moving_correlation(DF, 'yb', 'yy', window_frames)\n",
    "    DF['x_corr_rb'] = calculate_moving_correlation(DF, 'xr', 'xb', window_frames)\n",
    "    DF['y_corr_rb'] = calculate_moving_correlation(DF, 'yr', 'yb', window_frames)\n",
    "    \n",
    "    # Save the processed dataset to the specified directory\n",
    "    output_file = f\"{output_dir}Loopy_{dat_name}_processed.csv\"\n",
    "    DF.to_csv(output_file, index=False)\n",
    "    print(f\"Saved processed data to {output_file}.\")\n",
    "\n",
    "# Process all datasets in the list\n",
    "for dataset_name in dataset_names:\n",
    "    process_dataset(dataset_name)\n",
    "\n",
    "print(\"All datasets processed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56bf2dfe-858f-49f8-9690-bcde65d31c28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>xrc</th>\n",
       "      <th>yrc</th>\n",
       "      <th>xrf</th>\n",
       "      <th>yrf</th>\n",
       "      <th>xbc</th>\n",
       "      <th>ybc</th>\n",
       "      <th>xbf</th>\n",
       "      <th>ybf</th>\n",
       "      <th>xyc</th>\n",
       "      <th>yyc</th>\n",
       "      <th>...</th>\n",
       "      <th>vect_y_y</th>\n",
       "      <th>unit_vect_x_r</th>\n",
       "      <th>unit_vect_y_r</th>\n",
       "      <th>unit_vect_x_b</th>\n",
       "      <th>unit_vect_y_b</th>\n",
       "      <th>unit_vect_x_y</th>\n",
       "      <th>unit_vect_y_y</th>\n",
       "      <th>deg_ry</th>\n",
       "      <th>deg_rb</th>\n",
       "      <th>deg_by</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>813.748157</td>\n",
       "      <td>411.468976</td>\n",
       "      <td>841.726360</td>\n",
       "      <td>409.320596</td>\n",
       "      <td>803.035023</td>\n",
       "      <td>664.417601</td>\n",
       "      <td>778.179454</td>\n",
       "      <td>691.245274</td>\n",
       "      <td>1025.198740</td>\n",
       "      <td>401.020129</td>\n",
       "      <td>...</td>\n",
       "      <td>24.314813</td>\n",
       "      <td>0.997065</td>\n",
       "      <td>-0.076562</td>\n",
       "      <td>-0.679631</td>\n",
       "      <td>0.733554</td>\n",
       "      <td>-0.717827</td>\n",
       "      <td>0.696221</td>\n",
       "      <td>140.266385</td>\n",
       "      <td>137.205786</td>\n",
       "      <td>3.060600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>815.997536</td>\n",
       "      <td>411.895140</td>\n",
       "      <td>842.798184</td>\n",
       "      <td>407.661840</td>\n",
       "      <td>777.059541</td>\n",
       "      <td>665.894386</td>\n",
       "      <td>756.116163</td>\n",
       "      <td>694.524140</td>\n",
       "      <td>1024.929080</td>\n",
       "      <td>400.569711</td>\n",
       "      <td>...</td>\n",
       "      <td>24.320153</td>\n",
       "      <td>0.987754</td>\n",
       "      <td>-0.156021</td>\n",
       "      <td>-0.590414</td>\n",
       "      <td>0.807100</td>\n",
       "      <td>-0.720523</td>\n",
       "      <td>0.693431</td>\n",
       "      <td>145.073708</td>\n",
       "      <td>135.162402</td>\n",
       "      <td>9.911306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>818.619205</td>\n",
       "      <td>407.995233</td>\n",
       "      <td>843.195954</td>\n",
       "      <td>404.161857</td>\n",
       "      <td>761.221597</td>\n",
       "      <td>665.474297</td>\n",
       "      <td>763.140311</td>\n",
       "      <td>700.588511</td>\n",
       "      <td>1024.550603</td>\n",
       "      <td>400.568416</td>\n",
       "      <td>...</td>\n",
       "      <td>24.101949</td>\n",
       "      <td>0.988053</td>\n",
       "      <td>-0.154112</td>\n",
       "      <td>0.054561</td>\n",
       "      <td>0.998510</td>\n",
       "      <td>-0.721637</td>\n",
       "      <td>0.692272</td>\n",
       "      <td>145.055127</td>\n",
       "      <td>95.737665</td>\n",
       "      <td>49.317462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>820.900081</td>\n",
       "      <td>394.877467</td>\n",
       "      <td>843.426849</td>\n",
       "      <td>394.545665</td>\n",
       "      <td>753.502903</td>\n",
       "      <td>666.800267</td>\n",
       "      <td>772.678241</td>\n",
       "      <td>701.386882</td>\n",
       "      <td>1024.222991</td>\n",
       "      <td>400.789033</td>\n",
       "      <td>...</td>\n",
       "      <td>23.702317</td>\n",
       "      <td>0.999892</td>\n",
       "      <td>-0.014728</td>\n",
       "      <td>0.484880</td>\n",
       "      <td>0.874580</td>\n",
       "      <td>-0.722175</td>\n",
       "      <td>0.691710</td>\n",
       "      <td>137.078200</td>\n",
       "      <td>61.839218</td>\n",
       "      <td>75.238982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>820.430642</td>\n",
       "      <td>387.608287</td>\n",
       "      <td>842.961063</td>\n",
       "      <td>389.072835</td>\n",
       "      <td>755.299462</td>\n",
       "      <td>663.609011</td>\n",
       "      <td>770.080790</td>\n",
       "      <td>701.316197</td>\n",
       "      <td>1024.391713</td>\n",
       "      <td>400.041072</td>\n",
       "      <td>...</td>\n",
       "      <td>23.551657</td>\n",
       "      <td>0.997894</td>\n",
       "      <td>0.064866</td>\n",
       "      <td>0.364963</td>\n",
       "      <td>0.931022</td>\n",
       "      <td>-0.722686</td>\n",
       "      <td>0.691177</td>\n",
       "      <td>132.557487</td>\n",
       "      <td>64.875501</td>\n",
       "      <td>67.681986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2411</th>\n",
       "      <td>1164.005728</td>\n",
       "      <td>597.700526</td>\n",
       "      <td>1136.936311</td>\n",
       "      <td>568.575285</td>\n",
       "      <td>703.622442</td>\n",
       "      <td>339.471875</td>\n",
       "      <td>713.391266</td>\n",
       "      <td>373.346110</td>\n",
       "      <td>1018.202565</td>\n",
       "      <td>459.800252</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.377915</td>\n",
       "      <td>-0.680783</td>\n",
       "      <td>-0.732486</td>\n",
       "      <td>0.277093</td>\n",
       "      <td>0.960843</td>\n",
       "      <td>-0.951327</td>\n",
       "      <td>-0.308182</td>\n",
       "      <td>29.145480</td>\n",
       "      <td>153.181946</td>\n",
       "      <td>124.036466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2412</th>\n",
       "      <td>1139.741309</td>\n",
       "      <td>559.959324</td>\n",
       "      <td>1112.472235</td>\n",
       "      <td>532.674201</td>\n",
       "      <td>632.805029</td>\n",
       "      <td>358.064600</td>\n",
       "      <td>644.784066</td>\n",
       "      <td>393.255353</td>\n",
       "      <td>947.440519</td>\n",
       "      <td>441.983715</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.038315</td>\n",
       "      <td>-0.706899</td>\n",
       "      <td>-0.707315</td>\n",
       "      <td>0.322245</td>\n",
       "      <td>0.946656</td>\n",
       "      <td>-0.954470</td>\n",
       "      <td>-0.298308</td>\n",
       "      <td>27.660857</td>\n",
       "      <td>153.815582</td>\n",
       "      <td>126.154725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2413</th>\n",
       "      <td>1109.953263</td>\n",
       "      <td>514.291235</td>\n",
       "      <td>1081.035354</td>\n",
       "      <td>496.144789</td>\n",
       "      <td>592.690290</td>\n",
       "      <td>413.657986</td>\n",
       "      <td>622.559272</td>\n",
       "      <td>442.526801</td>\n",
       "      <td>874.926358</td>\n",
       "      <td>419.030871</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.359933</td>\n",
       "      <td>-0.847039</td>\n",
       "      <td>-0.531531</td>\n",
       "      <td>0.719043</td>\n",
       "      <td>0.694966</td>\n",
       "      <td>-0.998431</td>\n",
       "      <td>-0.056002</td>\n",
       "      <td>28.898540</td>\n",
       "      <td>168.084441</td>\n",
       "      <td>139.185901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2414</th>\n",
       "      <td>1068.683937</td>\n",
       "      <td>488.737348</td>\n",
       "      <td>1036.407360</td>\n",
       "      <td>480.491199</td>\n",
       "      <td>566.237935</td>\n",
       "      <td>459.396627</td>\n",
       "      <td>616.595072</td>\n",
       "      <td>484.740869</td>\n",
       "      <td>808.957729</td>\n",
       "      <td>384.281016</td>\n",
       "      <td>...</td>\n",
       "      <td>12.361350</td>\n",
       "      <td>-0.968879</td>\n",
       "      <td>-0.247533</td>\n",
       "      <td>0.893249</td>\n",
       "      <td>0.449563</td>\n",
       "      <td>-0.906548</td>\n",
       "      <td>0.422102</td>\n",
       "      <td>39.298979</td>\n",
       "      <td>167.615933</td>\n",
       "      <td>128.316954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2415</th>\n",
       "      <td>1018.710453</td>\n",
       "      <td>461.746180</td>\n",
       "      <td>988.495097</td>\n",
       "      <td>462.744696</td>\n",
       "      <td>594.117545</td>\n",
       "      <td>515.571926</td>\n",
       "      <td>646.033851</td>\n",
       "      <td>536.243929</td>\n",
       "      <td>736.949390</td>\n",
       "      <td>369.543835</td>\n",
       "      <td>...</td>\n",
       "      <td>25.234477</td>\n",
       "      <td>-0.999454</td>\n",
       "      <td>0.033029</td>\n",
       "      <td>0.929059</td>\n",
       "      <td>0.369932</td>\n",
       "      <td>-0.622252</td>\n",
       "      <td>0.782817</td>\n",
       "      <td>49.626455</td>\n",
       "      <td>156.395828</td>\n",
       "      <td>106.769373</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2416 rows Ã— 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              xrc         yrc          xrf         yrf         xbc  \\\n",
       "0      813.748157  411.468976   841.726360  409.320596  803.035023   \n",
       "1      815.997536  411.895140   842.798184  407.661840  777.059541   \n",
       "2      818.619205  407.995233   843.195954  404.161857  761.221597   \n",
       "3      820.900081  394.877467   843.426849  394.545665  753.502903   \n",
       "4      820.430642  387.608287   842.961063  389.072835  755.299462   \n",
       "...           ...         ...          ...         ...         ...   \n",
       "2411  1164.005728  597.700526  1136.936311  568.575285  703.622442   \n",
       "2412  1139.741309  559.959324  1112.472235  532.674201  632.805029   \n",
       "2413  1109.953263  514.291235  1081.035354  496.144789  592.690290   \n",
       "2414  1068.683937  488.737348  1036.407360  480.491199  566.237935   \n",
       "2415  1018.710453  461.746180   988.495097  462.744696  594.117545   \n",
       "\n",
       "             ybc         xbf         ybf          xyc         yyc  ...  \\\n",
       "0     664.417601  778.179454  691.245274  1025.198740  401.020129  ...   \n",
       "1     665.894386  756.116163  694.524140  1024.929080  400.569711  ...   \n",
       "2     665.474297  763.140311  700.588511  1024.550603  400.568416  ...   \n",
       "3     666.800267  772.678241  701.386882  1024.222991  400.789033  ...   \n",
       "4     663.609011  770.080790  701.316197  1024.391713  400.041072  ...   \n",
       "...          ...         ...         ...          ...         ...  ...   \n",
       "2411  339.471875  713.391266  373.346110  1018.202565  459.800252  ...   \n",
       "2412  358.064600  644.784066  393.255353   947.440519  441.983715  ...   \n",
       "2413  413.657986  622.559272  442.526801   874.926358  419.030871  ...   \n",
       "2414  459.396627  616.595072  484.740869   808.957729  384.281016  ...   \n",
       "2415  515.571926  646.033851  536.243929   736.949390  369.543835  ...   \n",
       "\n",
       "       vect_y_y  unit_vect_x_r  unit_vect_y_r  unit_vect_x_b  unit_vect_y_b  \\\n",
       "0     24.314813       0.997065      -0.076562      -0.679631       0.733554   \n",
       "1     24.320153       0.987754      -0.156021      -0.590414       0.807100   \n",
       "2     24.101949       0.988053      -0.154112       0.054561       0.998510   \n",
       "3     23.702317       0.999892      -0.014728       0.484880       0.874580   \n",
       "4     23.551657       0.997894       0.064866       0.364963       0.931022   \n",
       "...         ...            ...            ...            ...            ...   \n",
       "2411  -9.377915      -0.680783      -0.732486       0.277093       0.960843   \n",
       "2412  -8.038315      -0.706899      -0.707315       0.322245       0.946656   \n",
       "2413  -1.359933      -0.847039      -0.531531       0.719043       0.694966   \n",
       "2414  12.361350      -0.968879      -0.247533       0.893249       0.449563   \n",
       "2415  25.234477      -0.999454       0.033029       0.929059       0.369932   \n",
       "\n",
       "      unit_vect_x_y  unit_vect_y_y      deg_ry      deg_rb      deg_by  \n",
       "0         -0.717827       0.696221  140.266385  137.205786    3.060600  \n",
       "1         -0.720523       0.693431  145.073708  135.162402    9.911306  \n",
       "2         -0.721637       0.692272  145.055127   95.737665   49.317462  \n",
       "3         -0.722175       0.691710  137.078200   61.839218   75.238982  \n",
       "4         -0.722686       0.691177  132.557487   64.875501   67.681986  \n",
       "...             ...            ...         ...         ...         ...  \n",
       "2411      -0.951327      -0.308182   29.145480  153.181946  124.036466  \n",
       "2412      -0.954470      -0.298308   27.660857  153.815582  126.154725  \n",
       "2413      -0.998431      -0.056002   28.898540  168.084441  139.185901  \n",
       "2414      -0.906548       0.422102   39.298979  167.615933  128.316954  \n",
       "2415      -0.622252       0.782817   49.626455  156.395828  106.769373  \n",
       "\n",
       "[2416 rows x 37 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Path to the saved file\n",
    "file_path = \"/Users/ruzenkakaldenbach/Desktop/Behaviour/Loopy_preprocessed_data/Loopy_DYAD24NF__processed.csv\"\n",
    "\n",
    "# Load the CSV into a DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Print the DataFrame to the console\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9900e39d-738e-4f1d-85e3-274eeba17255",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
